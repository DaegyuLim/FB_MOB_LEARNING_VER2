[training]
n_epochs = 200
batch_size = 64
lr = 0.0001
optimizer = Adam
betas = [0.9, 0.999]
lr_schedule = True
lr_last = 0.00005
gaussian = true

[data]
seqeunce_length = 50
n_input_feature = 30
n_output_feature = 6
n_output = 12

[model]
network = GRU
save_every = 100
config_id = 00
name = mob_test
hidden_size = 150
num_layers = 1
bias = True
batch_first = True
dropout = 0.0
bidirectional = False    

[tcn]
kernel_size = 3
n_channels = [64, 64, 64]

[transformer]
d_model = 144
nhead = 6
num_encoder_layers = 2
num_decoder_layers = 2
dim_feedforward = 128